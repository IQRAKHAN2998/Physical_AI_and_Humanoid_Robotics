"use strict";(self.webpackChunkphysical_ai_and_humanoid_robotics=self.webpackChunkphysical_ai_and_humanoid_robotics||[]).push([[705],{6480:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"module-3-ai-robot-brain/overview","title":"Overview","description":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","source":"@site/docs/module-3-ai-robot-brain/01-overview.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/overview","permalink":"/docs/module-3-ai-robot-brain/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Simulating Sensors","permalink":"/docs/module-2-digital-twin/simulating-sensors"},"next":{"title":"NVIDIA Isaac Sim","permalink":"/docs/module-3-ai-robot-brain/isaac-sim"}}');var t=i(4848),a=i(8453);const r={sidebar_position:1,title:"Overview"},s=void 0,d={},l=[{value:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)",id:"module-3-the-ai-robot-brain-nvidia-isaac",level:3}];function c(e){const n={h3:"h3",p:"p",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h3,{id:"module-3-the-ai-robot-brain-nvidia-isaac",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)"}),"\n",(0,t.jsx)(n.p,{children:"Focus: Advanced perception and training."}),"\n",(0,t.jsx)(n.p,{children:"Module 3 focuses on the AI-Robot Brain, leveraging NVIDIA Isaac\u2122 to enable humanoid robots with advanced perception, decision-making, and learning capabilities. In this module, students explore how AI algorithms can be integrated with robotics middleware to create intelligent agents capable of understanding their environment and executing complex tasks."}),"\n",(0,t.jsx)(n.p,{children:"Students learn to design and train AI models for perception, including object recognition, gesture detection, and scene understanding. Using Isaac Sim, learners simulate robot behaviors in virtual environments, testing navigation, manipulation, and interaction algorithms safely before real-world deployment. The module also covers Isaac ROS integration, enabling communication between AI models and ROS 2 controllers for real-time decision-making."}),"\n",(0,t.jsx)(n.p,{children:"Practical exercises include training reinforcement learning agents to perform locomotion and manipulation tasks, integrating sensor inputs from simulated cameras and LiDAR, and executing high-level planning using Nav2 navigation stacks. By the end of this module, students understand how AI models interact with physical robot components, making autonomous decisions while responding to dynamic environments."}),"\n",(0,t.jsx)(n.p,{children:"This module provides a solid foundation in AI-driven robotic control, preparing learners to build intelligent humanoid robots that combine perception, planning, and action for real-world applications."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var o=i(6540);const t={},a=o.createContext(t);function r(e){const n=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);