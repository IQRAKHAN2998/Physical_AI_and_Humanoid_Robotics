---
sidebar_position: 4
title: Capstone Project
---

### Capstone Project: The Autonomous Humanoid

The Capstone Project is designed to synthesize all the skills learned throughout the course, challenging students to build a fully autonomous humanoid robot in a simulated environment. This project integrates voice recognition, cognitive planning, perception, navigation, and manipulation into a single cohesive system.

Students program a humanoid robot to respond to natural language commands using the Voice-to-Action pipeline. For example, the instruction "Pick up the red cube from the table" triggers the robot to plan its path, avoid obstacles, and approach the target. The robot uses its simulated sensors—including cameras, LiDAR, and depth sensors—to identify objects, understand the environment, and make real-time decisions.

Cognitive Planning and LLM integration allow the robot to break down complex tasks into sequential actions, while ROS 2 nodes control motion, perception, and manipulation. Students must also ensure smooth interaction between AI perception modules, navigation stacks like Nav2, and manipulation controllers, handling unexpected situations such as obstacles or missing objects.

By completing this Capstone Project, learners demonstrate mastery of Vision-Language-Action concepts, sensor integration, AI-driven decision-making, and humanoid robotics control. The project provides a realistic, hands-on experience, preparing students to design autonomous robots capable of intelligent interaction and task execution in both simulated and real-world environments.
